C:\Windows\System32>docker run -it --name spark-lab -p 8080:8080 -p 4040:4040 apache/spark:latest /opt/spark/bin/spark-shell
WARNING: Using incubator modules: jdk.incubator.vector
Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 4.1.1
      /_/

Using Scala version 2.13.17 (OpenJDK 64-Bit Server VM, Java 21.0.9)
Type in expressions to have them evaluated.
Type :help for more information.
26/01/12 17:21:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Spark context Web UI available at http://333ca35c21dd:4040
Spark context available as 'sc' (master = local[*], app id = local-1768238494188).
Spark session available as 'spark'.

scala> spark.version26/01/12 17:33:18 WARN jline: Failed to save history
java.nio.file.AccessDeniedException: /nonexistent
        at java.base/sun.nio.fs.UnixException.translateToIOException(UnixException.java:90)
        at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:106)
        at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:111)
        at java.base/sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:462)
        at java.base/java.nio.file.Files.createDirectory(Files.java:700)
        at java.base/java.nio.file.Files.createAndCheckIsDirectory(Files.java:808)
        at java.base/java.nio.file.Files.createDirectories(Files.java:794)
        at org.jline.reader.impl.history.DefaultHistory.internalWrite(DefaultHistory.java:223)
        at org.jline.reader.impl.history.DefaultHistory.save(DefaultHistory.java:215)
        at org.jline.reader.impl.history.DefaultHistory.add(DefaultHistory.java:388)
        at org.jline.reader.impl.LineReaderImpl.finish(LineReaderImpl.java:1196)
        at org.jline.reader.impl.LineReaderImpl.finishBuffer(LineReaderImpl.java:1165)
        at org.jline.reader.impl.LineReaderImpl.readLine(LineReaderImpl.java:733)
        at org.jline.reader.impl.LineReaderImpl.readLine(LineReaderImpl.java:511)
        at scala.tools.nsc.interpreter.jline.Reader.readOneLine(Reader.scala:43)
        at scala.tools.nsc.interpreter.shell.InteractiveReader.readLine(InteractiveReader.scala:38)
        at scala.tools.nsc.interpreter.shell.InteractiveReader.readLine$(InteractiveReader.scala:38)
        at scala.tools.nsc.interpreter.jline.Reader.readLine(Reader.scala:33)
        at scala.tools.nsc.interpreter.shell.ILoop.readOneLine(ILoop.scala:453)
        at scala.tools.nsc.interpreter.shell.ILoop.loop(ILoop.scala:458)
        at scala.tools.nsc.interpreter.shell.ILoop.run(ILoop.scala:991)
        at org.apache.spark.repl.Main$.doMain(Main.scala:87)
        at org.apache.spark.repl.Main$.main(Main.scala:62)
        at org.apache.spark.repl.Main.main(Main.scala)
        at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
        at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
        at java.base/java.lang.reflect.Method.invoke(Method.java:580)
        at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
        at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:1030)
        at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:203)
        at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:226)
        at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:95)
        at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1168)
        at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1177)
        at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)

val res0: String = 4.1.1


scala> val df = spark.createDataFrame(Seq((1, "Alice"), (2, "Bob"))).toDF("id", "name") df.show()26/01/12 17:37:49 WARN jline: Failed to save history
java.nio.file.AccessDeniedException: /nonexistent
        at java.base/sun.nio.fs.UnixException.translateToIOException(UnixException.java:90)
        at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:106)
        at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:111)
        at java.base/sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:462)
        at java.base/java.nio.file.Files.createDirectory(Files.java:700)
        at java.base/java.nio.file.Files.createAndCheckIsDirectory(Files.java:808)
        at java.base/java.nio.file.Files.createDirectories(Files.java:794)
        at org.jline.reader.impl.history.DefaultHistory.internalWrite(DefaultHistory.java:223)
        at org.jline.reader.impl.history.DefaultHistory.save(DefaultHistory.java:215)
        at org.jline.reader.impl.history.DefaultHistory.add(DefaultHistory.java:388)
        at org.jline.reader.impl.LineReaderImpl.finish(LineReaderImpl.java:1196)
        at org.jline.reader.impl.LineReaderImpl.finishBuffer(LineReaderImpl.java:1165)
        at org.jline.reader.impl.LineReaderImpl.readLine(LineReaderImpl.java:733)
        at org.jline.reader.impl.LineReaderImpl.readLine(LineReaderImpl.java:511)
        at scala.tools.nsc.interpreter.jline.Reader.readOneLine(Reader.scala:43)
        at scala.tools.nsc.interpreter.shell.InteractiveReader.readLine(InteractiveReader.scala:38)
        at scala.tools.nsc.interpreter.shell.InteractiveReader.readLine$(InteractiveReader.scala:38)
        at scala.tools.nsc.interpreter.jline.Reader.readLine(Reader.scala:33)
        at scala.tools.nsc.interpreter.shell.ILoop.readOneLine(ILoop.scala:453)
        at scala.tools.nsc.interpreter.shell.ILoop.loop(ILoop.scala:458)
        at scala.tools.nsc.interpreter.shell.ILoop.run(ILoop.scala:991)
        at org.apache.spark.repl.Main$.doMain(Main.scala:87)
        at org.apache.spark.repl.Main$.main(Main.scala:62)
        at org.apache.spark.repl.Main.main(Main.scala)
        at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
        at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
        at java.base/java.lang.reflect.Method.invoke(Method.java:580)
        at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
        at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:1030)
        at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:203)
        at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:226)
        at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:95)
        at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1168)
        at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1177)
        at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)

                                                                                          ^
       error: ';' expected but '.' found.


scala> val df = spark.createDataFrame(Seq((1, "Alice"), (2, "Bob"))).toDF("id", "name")26/01/12 17:43:56 WARN jline: Failed to save history
java.nio.file.AccessDeniedException: /nonexistent
        at java.base/sun.nio.fs.UnixException.translateToIOException(UnixException.java:90)
        at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:106)
        at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:111)
        at java.base/sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:462)
        at java.base/java.nio.file.Files.createDirectory(Files.java:700)
        at java.base/java.nio.file.Files.createAndCheckIsDirectory(Files.java:808)
        at java.base/java.nio.file.Files.createDirectories(Files.java:794)
        at org.jline.reader.impl.history.DefaultHistory.internalWrite(DefaultHistory.java:223)
        at org.jline.reader.impl.history.DefaultHistory.save(DefaultHistory.java:215)
        at org.jline.reader.impl.history.DefaultHistory.add(DefaultHistory.java:388)
        at org.jline.reader.impl.LineReaderImpl.finish(LineReaderImpl.java:1196)
        at org.jline.reader.impl.LineReaderImpl.finishBuffer(LineReaderImpl.java:1165)
        at org.jline.reader.impl.LineReaderImpl.readLine(LineReaderImpl.java:733)
        at org.jline.reader.impl.LineReaderImpl.readLine(LineReaderImpl.java:511)
        at scala.tools.nsc.interpreter.jline.Reader.readOneLine(Reader.scala:43)
        at scala.tools.nsc.interpreter.shell.InteractiveReader.readLine(InteractiveReader.scala:38)
        at scala.tools.nsc.interpreter.shell.InteractiveReader.readLine$(InteractiveReader.scala:38)
        at scala.tools.nsc.interpreter.jline.Reader.readLine(Reader.scala:33)
        at scala.tools.nsc.interpreter.shell.ILoop.readOneLine(ILoop.scala:453)
        at scala.tools.nsc.interpreter.shell.ILoop.loop(ILoop.scala:458)
        at scala.tools.nsc.interpreter.shell.ILoop.run(ILoop.scala:991)
        at org.apache.spark.repl.Main$.doMain(Main.scala:87)
        at org.apache.spark.repl.Main$.main(Main.scala:62)
        at org.apache.spark.repl.Main.main(Main.scala)
        at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
        at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
        at java.base/java.lang.reflect.Method.invoke(Method.java:580)
        at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
        at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:1030)
        at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:203)
        at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:226)
        at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:95)
        at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1168)
        at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1177)
        at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)

val df: org.apache.spark.sql.DataFrame = [id: int, name: string]

scala> df.show()26/01/12 17:44:06 WARN jline: Failed to save history
java.nio.file.AccessDeniedException: /nonexistent
        at java.base/sun.nio.fs.UnixException.translateToIOException(UnixException.java:90)
        at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:106)
        at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:111)
        at java.base/sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:462)
        at java.base/java.nio.file.Files.createDirectory(Files.java:700)
        at java.base/java.nio.file.Files.createAndCheckIsDirectory(Files.java:808)
        at java.base/java.nio.file.Files.createDirectories(Files.java:794)
        at org.jline.reader.impl.history.DefaultHistory.internalWrite(DefaultHistory.java:223)
        at org.jline.reader.impl.history.DefaultHistory.save(DefaultHistory.java:215)
        at org.jline.reader.impl.history.DefaultHistory.add(DefaultHistory.java:388)
        at org.jline.reader.impl.LineReaderImpl.finish(LineReaderImpl.java:1196)
        at org.jline.reader.impl.LineReaderImpl.finishBuffer(LineReaderImpl.java:1165)
        at org.jline.reader.impl.LineReaderImpl.readLine(LineReaderImpl.java:733)
        at org.jline.reader.impl.LineReaderImpl.readLine(LineReaderImpl.java:511)
        at scala.tools.nsc.interpreter.jline.Reader.readOneLine(Reader.scala:43)
        at scala.tools.nsc.interpreter.shell.InteractiveReader.readLine(InteractiveReader.scala:38)
        at scala.tools.nsc.interpreter.shell.InteractiveReader.readLine$(InteractiveReader.scala:38)
        at scala.tools.nsc.interpreter.jline.Reader.readLine(Reader.scala:33)
        at scala.tools.nsc.interpreter.shell.ILoop.readOneLine(ILoop.scala:453)
        at scala.tools.nsc.interpreter.shell.ILoop.loop(ILoop.scala:458)
        at scala.tools.nsc.interpreter.shell.ILoop.run(ILoop.scala:991)
        at org.apache.spark.repl.Main$.doMain(Main.scala:87)
        at org.apache.spark.repl.Main$.main(Main.scala:62)
        at org.apache.spark.repl.Main.main(Main.scala)
        at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
        at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
        at java.base/java.lang.reflect.Method.invoke(Method.java:580)
        at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
        at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:1030)
        at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:203)
        at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:226)
        at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:95)
        at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1168)
        at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1177)
        at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)

+---+-----+
| id| name|
+---+-----+
|  1|Alice|
|  2|  Bob|
+---+-----+



scala> val text = sc.parallelize(seq("Spark is fast", "Spark is easy", "Docker makes Spark simple"))26/01/12 19:39:32 WARN jline: Failed to save history
java.nio.file.AccessDeniedException: /nonexistent
        at java.base/sun.nio.fs.UnixException.translateToIOException(UnixException.java:90)
        at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:106)
        at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:111)
        at java.base/sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:462)
        at java.base/java.nio.file.Files.createDirectory(Files.java:700)
        at java.base/java.nio.file.Files.createAndCheckIsDirectory(Files.java:808)
        at java.base/java.nio.file.Files.createDirectories(Files.java:794)
        at org.jline.reader.impl.history.DefaultHistory.internalWrite(DefaultHistory.java:223)
        at org.jline.reader.impl.history.DefaultHistory.save(DefaultHistory.java:215)
        at org.jline.reader.impl.history.DefaultHistory.add(DefaultHistory.java:388)
        at org.jline.reader.impl.LineReaderImpl.finish(LineReaderImpl.java:1196)
        at org.jline.reader.impl.LineReaderImpl.finishBuffer(LineReaderImpl.java:1165)
        at org.jline.reader.impl.LineReaderImpl.readLine(LineReaderImpl.java:733)
        at org.jline.reader.impl.LineReaderImpl.readLine(LineReaderImpl.java:511)
        at scala.tools.nsc.interpreter.jline.Reader.readOneLine(Reader.scala:43)
        at scala.tools.nsc.interpreter.shell.InteractiveReader.readLine(InteractiveReader.scala:38)
        at scala.tools.nsc.interpreter.shell.InteractiveReader.readLine$(InteractiveReader.scala:38)
        at scala.tools.nsc.interpreter.jline.Reader.readLine(Reader.scala:33)
        at scala.tools.nsc.interpreter.shell.ILoop.readOneLine(ILoop.scala:453)
        at scala.tools.nsc.interpreter.shell.ILoop.loop(ILoop.scala:458)
        at scala.tools.nsc.interpreter.shell.ILoop.run(ILoop.scala:991)
        at org.apache.spark.repl.Main$.doMain(Main.scala:87)
        at org.apache.spark.repl.Main$.main(Main.scala:62)
        at org.apache.spark.repl.Main.main(Main.scala)
        at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
        at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
        at java.base/java.lang.reflect.Method.invoke(Method.java:580)
        at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
        at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:1030)
        at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:203)
        at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:226)
        at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:95)
        at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1168)
        at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1177)
        at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)

                                 ^
       error: not found: value seq
       Error occurred in an application involving default arguments.


scala> val text = sc.parallelize(Seq("Spark is fast", "Spark is easy", "Docker makes Spark simple"))26/01/12 19:52:10 WARN jline: Failed to save history
java.nio.file.AccessDeniedException: /nonexistent
        at java.base/sun.nio.fs.UnixException.translateToIOException(UnixException.java:90)
        at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:106)
        at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:111)
        at java.base/sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:462)
        at java.base/java.nio.file.Files.createDirectory(Files.java:700)
        at java.base/java.nio.file.Files.createAndCheckIsDirectory(Files.java:808)
        at java.base/java.nio.file.Files.createDirectories(Files.java:794)
        at org.jline.reader.impl.history.DefaultHistory.internalWrite(DefaultHistory.java:223)
        at org.jline.reader.impl.history.DefaultHistory.save(DefaultHistory.java:215)
        at org.jline.reader.impl.history.DefaultHistory.add(DefaultHistory.java:388)
        at org.jline.reader.impl.LineReaderImpl.finish(LineReaderImpl.java:1196)
        at org.jline.reader.impl.LineReaderImpl.finishBuffer(LineReaderImpl.java:1165)
        at org.jline.reader.impl.LineReaderImpl.readLine(LineReaderImpl.java:733)
        at org.jline.reader.impl.LineReaderImpl.readLine(LineReaderImpl.java:511)
        at scala.tools.nsc.interpreter.jline.Reader.readOneLine(Reader.scala:43)
        at scala.tools.nsc.interpreter.shell.InteractiveReader.readLine(InteractiveReader.scala:38)
        at scala.tools.nsc.interpreter.shell.InteractiveReader.readLine$(InteractiveReader.scala:38)
        at scala.tools.nsc.interpreter.jline.Reader.readLine(Reader.scala:33)
        at scala.tools.nsc.interpreter.shell.ILoop.readOneLine(ILoop.scala:453)
        at scala.tools.nsc.interpreter.shell.ILoop.loop(ILoop.scala:458)
        at scala.tools.nsc.interpreter.shell.ILoop.run(ILoop.scala:991)
        at org.apache.spark.repl.Main$.doMain(Main.scala:87)
        at org.apache.spark.repl.Main$.main(Main.scala:62)
        at org.apache.spark.repl.Main.main(Main.scala)
        at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
        at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
        at java.base/java.lang.reflect.Method.invoke(Method.java:580)
        at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
        at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:1030)
        at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:203)
        at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:226)
        at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:95)
        at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1168)
        at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1177)
        at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)

val text: org.apache.spark.rdd.RDD[String] = ParallelCollectionRDD[0] at parallelize at <console>:1

scala> val counts = text.flatMap(line => line.split(" ")).map(word => (word, 1)).reduceByKey(_+_)26/01/13 01:33:31 WARN jline: Failed to save history
java.nio.file.AccessDeniedException: /nonexistent
        at java.base/sun.nio.fs.UnixException.translateToIOException(UnixException.java:90)
        at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:106)
        at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:111)
        at java.base/sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:462)
        at java.base/java.nio.file.Files.createDirectory(Files.java:700)
        at java.base/java.nio.file.Files.createAndCheckIsDirectory(Files.java:808)
        at java.base/java.nio.file.Files.createDirectories(Files.java:794)
        at org.jline.reader.impl.history.DefaultHistory.internalWrite(DefaultHistory.java:223)
        at org.jline.reader.impl.history.DefaultHistory.save(DefaultHistory.java:215)
        at org.jline.reader.impl.history.DefaultHistory.add(DefaultHistory.java:388)
        at org.jline.reader.impl.LineReaderImpl.finish(LineReaderImpl.java:1196)
        at org.jline.reader.impl.LineReaderImpl.finishBuffer(LineReaderImpl.java:1165)
        at org.jline.reader.impl.LineReaderImpl.readLine(LineReaderImpl.java:733)
        at org.jline.reader.impl.LineReaderImpl.readLine(LineReaderImpl.java:511)
        at scala.tools.nsc.interpreter.jline.Reader.readOneLine(Reader.scala:43)
        at scala.tools.nsc.interpreter.shell.InteractiveReader.readLine(InteractiveReader.scala:38)
        at scala.tools.nsc.interpreter.shell.InteractiveReader.readLine$(InteractiveReader.scala:38)
        at scala.tools.nsc.interpreter.jline.Reader.readLine(Reader.scala:33)
        at scala.tools.nsc.interpreter.shell.ILoop.readOneLine(ILoop.scala:453)
        at scala.tools.nsc.interpreter.shell.ILoop.loop(ILoop.scala:458)
        at scala.tools.nsc.interpreter.shell.ILoop.run(ILoop.scala:991)
        at org.apache.spark.repl.Main$.doMain(Main.scala:87)
        at org.apache.spark.repl.Main$.main(Main.scala:62)
        at org.apache.spark.repl.Main.main(Main.scala)
        at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
        at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
        at java.base/java.lang.reflect.Method.invoke(Method.java:580)
        at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
        at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:1030)
        at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:203)
        at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:226)
        at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:95)
        at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1168)
        at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1177)
        at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)

val counts: org.apache.spark.rdd.RDD[(String, Int)] = ShuffledRDD[3] at reduceByKey at <console>:1

scala> counts.collect().foreach(println)26/01/13 01:34:37 WARN jline: Failed to save history
java.nio.file.AccessDeniedException: /nonexistent
        at java.base/sun.nio.fs.UnixException.translateToIOException(UnixException.java:90)
        at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:106)
        at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:111)
        at java.base/sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:462)
        at java.base/java.nio.file.Files.createDirectory(Files.java:700)
        at java.base/java.nio.file.Files.createAndCheckIsDirectory(Files.java:808)
        at java.base/java.nio.file.Files.createDirectories(Files.java:794)
        at org.jline.reader.impl.history.DefaultHistory.internalWrite(DefaultHistory.java:223)
        at org.jline.reader.impl.history.DefaultHistory.save(DefaultHistory.java:215)
        at org.jline.reader.impl.history.DefaultHistory.add(DefaultHistory.java:388)
        at org.jline.reader.impl.LineReaderImpl.finish(LineReaderImpl.java:1196)
        at org.jline.reader.impl.LineReaderImpl.finishBuffer(LineReaderImpl.java:1165)
        at org.jline.reader.impl.LineReaderImpl.readLine(LineReaderImpl.java:733)
        at org.jline.reader.impl.LineReaderImpl.readLine(LineReaderImpl.java:511)
        at scala.tools.nsc.interpreter.jline.Reader.readOneLine(Reader.scala:43)
        at scala.tools.nsc.interpreter.shell.InteractiveReader.readLine(InteractiveReader.scala:38)
        at scala.tools.nsc.interpreter.shell.InteractiveReader.readLine$(InteractiveReader.scala:38)
        at scala.tools.nsc.interpreter.jline.Reader.readLine(Reader.scala:33)
        at scala.tools.nsc.interpreter.shell.ILoop.readOneLine(ILoop.scala:453)
        at scala.tools.nsc.interpreter.shell.ILoop.loop(ILoop.scala:458)
        at scala.tools.nsc.interpreter.shell.ILoop.run(ILoop.scala:991)
        at org.apache.spark.repl.Main$.doMain(Main.scala:87)
        at org.apache.spark.repl.Main$.main(Main.scala:62)
        at org.apache.spark.repl.Main.main(Main.scala)
        at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
        at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
        at java.base/java.lang.reflect.Method.invoke(Method.java:580)
        at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
        at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:1030)
        at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:203)
        at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:226)
        at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:95)
        at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1168)
        at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1177)
        at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)

(Docker,1)
(makes,1)
(easy,1)
(fast,1)
(Spark,3)
(is,2)
(simple,1)
